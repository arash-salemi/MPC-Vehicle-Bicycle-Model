function [x_new, output]   =  Model_GRU(x,u)

h_t  =  x(4 : end);
% Initialize weights and biases
W_input  =  [-0.095897 -0.012435 0.027793 0.371231 -0.005094 0.124832;-0.001613 0.000280 -0.001032 0.120837 -0.051541 -0.089163;-0.020829 0.003020 0.000128 -0.006392 0.119840 -0.011985;0.028522 -0.010024 -0.006695 -0.344397 -0.163646 -0.246519;-0.014741 -0.006104 -0.004543 0.112781 -0.026581 -0.000932;-0.007655 0.006522 0.001021 -0.541686 -0.135704 -0.007165;0.037126 0.004060 0.002918 0.086177 0.001136 0.029026;0.002731 -0.000119 -0.000031 0.041135 -0.030265 0.003032;-0.303361 -0.174777 0.058984 -1.088399 -0.456023 -0.266408;-0.682596 0.071107 -0.007277 -1.080279 -0.588972 -0.674350;-0.492108 -0.059440 0.044719 0.031613 -0.562382 -0.583926;-0.108377 -0.227406 -0.161012 -0.701523 0.055240 -0.152693;-0.120685 -0.201047 -0.488457 -0.981044 -0.293663 -0.192205;-0.091291 -0.368637 -0.245565 -0.688684 -0.521099 -0.461413;-0.052068 -0.011567 -0.023209 0.221322 0.022841 -0.018732;-0.465640 -0.004387 -0.037150 -0.965176 -0.472427 -0.608690;-0.013075 -0.021464 -0.008653 0.443277 0.355848 0.100046;0.008791 0.008809 0.004294 0.418115 -0.046355 -0.381566;0.078418 -0.003842 0.010197 0.153296 -0.005085 -0.137296;0.029651 0.026241 0.015859 -0.127482 0.100388 0.586224;-0.028239 -0.037358 -0.032341 -0.221630 0.039616 -0.224430;-0.075767 0.007184 -0.007589 -0.021942 0.567109 -0.033828;-0.055810 0.077036 0.047819 -0.022970 -0.067335 0.124617;0.055425 0.009086 0.011745 -0.309683 0.625754 -0.110820;];
W_recurrent  =  [0.449549 0.025030 -0.096241 -0.168294 -0.235541 0.000154 -0.286506 -0.000000;-0.000000 0.000000 0.004807 0.000000 -0.000000 0.064231 -0.000000 0.024651;0.485105 0.052874 0.000033 -0.027222 -0.000000 0.376345 -0.000000 -0.000000;0.001067 -0.000073 -0.000000 0.094900 -0.001176 0.090062 0.000000 -0.052772;-0.000014 0.000096 0.070818 -0.000116 -0.001819 -0.000000 0.000021 -0.031904;-0.075881 -0.059038 -0.000000 -0.009897 -0.000000 -0.000000 -0.001961 0.022182;0.000000 -0.037331 -0.000000 -0.000000 -0.000632 -0.000009 0.000667 -0.000000;-0.078798 -0.000033 -0.011031 -0.000003 0.000052 0.000000 0.000000 0.032599;-0.573147 0.000000 0.151396 -0.000011 1.082723 -0.816462 0.652375 -0.000000;-0.382626 -0.000039 0.008461 -0.253424 0.018146 -0.200148 1.273786 0.000000;-0.021385 -0.000000 0.498021 -0.297493 0.368878 -0.457074 0.526535 -0.050971;-0.005362 -0.231979 -0.010862 -0.000000 0.009229 0.000005 0.252313 0.447642;-0.108325 -0.144418 0.031101 -0.000121 0.296174 -0.068469 0.285247 -0.000000;-0.101816 -0.000001 0.268416 -0.000000 0.414597 -0.267433 0.478665 0.000000;-0.057857 0.000000 0.033577 0.000008 0.090569 -0.000002 0.054693 0.012192;-0.064325 -0.120602 0.000030 -0.259008 0.775705 -0.380701 0.572294 -0.004287;0.000000 0.000000 0.000000 -0.000000 0.001459 -0.000000 0.004608 -0.000000;-0.016701 -0.094781 -0.000000 -0.000000 0.000000 -0.000000 0.000000 0.022603;-0.011072 -0.006802 -0.003487 -0.000000 0.000000 -0.159166 0.000000 -0.018679;-0.099606 0.000000 0.005900 -0.273327 0.001836 -0.000673 0.005513 -0.000001;-0.000000 -0.000000 0.019067 0.000004 -0.000000 -0.000000 -0.000000 -0.246290;-0.083940 -0.000000 0.000559 0.003144 0.011304 -0.000065 0.002755 -0.023331;-0.000002 -0.000000 0.090047 -0.000000 0.017483 -0.000001 0.000000 -0.003226;0.000002 0.000000 0.034014 0.000005 0.000000 -0.000000 0.000416 -0.058670;];

W_dense  = [0.792528 0.899694 0.410716 0.321609 -0.486353 0.538735 -0.320163 -0.824348;0.928638 0.112599 -0.479506 0.023697 0.092886 0.233405 0.061675 1.027291;0.620761 -0.762181 -0.405004 1.095673 -0.361138 -0.155618 -0.394896 -0.451011;];


bias  =  [0.066898;0.135457;0.237060;0.274518;0.456006;0.272725;0.185509;-0.027074;-1.068504;-0.939111;-1.220924;-0.671026;-1.704713;-0.605181;-0.165316;-1.658573;-0.092363;-0.071420;0.068987;0.003822;-0.087872;0.075973;-0.021838;0.016971;0.066898;0.135457;0.237060;0.274518;0.456006;0.272725;0.185509;-0.027074;-1.068504;-0.939111;-1.220924;-0.671026;-1.704713;-0.605181;-0.165316;-1.658573;-0.262571;-0.034982;0.072780;-0.067652;0.011298;0.081524;-0.047508;0.006683;];

b_dense = [0.111769;0.219248;0.135490;];


%% Given shapes
W_is  =  size(W_input,1)/3;
W_rs  =  size(W_recurrent);
bias_shape  =  size(bias);
input_shape  =  size(u);

W_r = W_input(1 : W_is, : );
W_z = W_input(W_is + 1 : 2*W_is, : );
W_h = W_input(2*W_is + 1 : end, : );

R_r = W_recurrent(1 : W_is, : );
R_z = W_recurrent(W_is + 1 : 2*W_is, : );
R_h = W_recurrent(2*W_is + 1 : end, : );

BW_r = bias(1 : W_is, : );
BW_z = bias(W_is + 1 : 2*W_is, : );
BW_h = bias(2*W_is + 1 : 3*W_is, : );

BR_r = bias(3*W_is + 1 : 4*W_is, : );
BR_z = bias(4*W_is + 1 : 5*W_is, : );
BR_h = bias(5*W_is + 1 : end, : );

% Initialize hidden state
%h_t =  zeros(W_rs,1);

%Reset Gate
r_t  =  sigmoid(W_r*u + R_r*h_t + BW_r + BR_r);
%Update Gate
z_t  =  sigmoid(W_z*u + R_z*h_t + BW_z + BR_z);

% Candidate State
h_t_hat  =  tanh(W_h*u + r_t.*(R_h*h_t  + BR_h) + BW_h);

% s1 = size(z_t)
% s2 = size(h_t_hat)
% s3 = size(h_t)

% Hidden State
h_t = (1-z_t).*h_t_hat + z_t.*h_t;

% Apply activation function
out_gru  =  h_t;

% Fully connected Layer
output  =  W_dense*out_gru  +  b_dense;

x_new  =  [output(1, : ); output(2, : );output(3, : ); h_t];



